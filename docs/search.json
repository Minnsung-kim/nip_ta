{
  "articles": [
    {
      "path": "classifier_bert.html",
      "title": "캡스톤 프로젝트",
      "description": "우리는 한 학기 과정의 핵심 내용을 실습을 통해서 다시한번 다지고 나갑니다.\n",
      "author": [
        {
          "name": "김민성",
          "url": "https://minnsung-kim.github.io"
        }
      ],
      "date": "2022-12-16",
      "contents": "\n\nContents\n텍스트 데이터 수집\n수집전략\n준비사항\n데이터 수집\n\n정규표현식의 이해\n패턴 검색\n\nCorrelation Analysis\nTerm Frequency\n연관분석\n\nBinary Term Frequency\n기반 DTM 생성\n불용어 제거\nTransactions 생성하기\n연관규칙 생성하기\n연관규칙 시각화하기\n\n단어의 계층적 군집분석\n희박 단어의 제거\n비상사도 행렬 생성\nClustering\n군집 개수 선정 및\n시각화\n군집의 해석\n\n기사의 계층적 군집분석\n비상사도 행렬 생성\nClustering\n군집 개수 선정 및\n시각화\n군집의 해석\n기사 군집 1\n\nTopic 분석\n희박 단어의 제거\nOTF 계산\n불용어 제거\n불용어 제거\nTopic 개수 구하기\nTop beta 단어의 시각화\n문서에서의 토픽의 비중\n토픽이 포함된 문서 조회\n문서의 토픽 분해\n토픽의 단어 분해\n\n이진분류 모형\n패키지 로드하기\n파생변수 만들기\n불균형 데이터의 언더\n샘플링\n데이터셋 분리\ntokenize 반복기 정의\nFrequency 기반의 DTM\n생성\nN-Grams 기반의 DTM 생성\nTF-IDF 기반의 DTM 생성\nDTM의 크기 비교\nFrequency 기반 모델링\n모델의 이해\n모델의 평가\n\n\n텍스트 데이터 수집\n수집전략\n“월드컵”이라는 키워드로 네이버 뉴스 데이터를 수집합니다.\n날짜 정렬과 유사도 정렬 두 가지 방법 모두 사용합니다.\n준비사항\n클라이언트 아이디 : Kw6jqiYX_rA3Cud_pjJb\n클라이언트 키 : p57_rPaA85\n데이터 수집\n인증키와 키워드 입력 client_id, client_secret는 사용자의 API 인증키를\n넣습니다.\n\n\nlibrary(koscrap)\n# Naver 뉴스 API 인증키\nclient_id <- \"Kw6jqiYX_rA3Cud_pjJb\"\nclient_secret <- \"p57_rPaA85\"\n# 검색 키워드\nkeyword <- \"월드컵\"\n\n\n\n날짜 기준 정렬로 1,000건의 뉴스를 수집합니다.\n\n\nn <- 1000\n# 날짜 정렬 수집\nnews_worldcup_date <- search_naver(\n  keyword, client_id = client_id, client_secret = client_secret,\n  do_done = TRUE, max_record = n\n)\n\n\n\n유사도 기준 정렬로 1,000건의 뉴스를 수집합니다.\n\n\n# 유사도 정렬 수집\nnews_worldcup_sim <- search_naver(\n  keyword, client_id = client_id, client_secret = client_secret, sort = \"sim\",\n  do_done = TRUE, max_record = n\n)\n\n\n\n각각 2749645건의 데이터가 수집되었습니다. 변수의 개수는\n7개입니다.\n\n\ndim(news_worldcup_date)\ndim(news_worldcup_sim)\n\n\n\n앞부분 몇 건과 뒷부분 몇 건을 조회해 봅니다.\n\n\nhead(news_worldcup_date)\ntail(news_worldcup_sim)\n\n\n\n###간단한 데이터 요약\n빈발단어를 워드클라우드로 시각회하는 함수를 만듦니다.\n\n\n# create UDF\ncreate_wordcloud <- function(data, remove_n = 5, min_freq = 5, background = \"white\") {\n  data %>% \n    filter(nchar(description_text) > 0) %>%   \n    tidytext::unnest_tokens(noun, description_text, bitTA::morpho_mecab, type = \"noun\") %>% \n    group_by(noun) %>% \n    count() %>% \n    arrange(desc(n)) %>%     \n    ungroup() %>%\n    filter(n >= min_freq) %>% \n    filter(row_number() > remove_n) %>% \n    wordcloud2::wordcloud2(backgroundColor = background, \n                           fontFamily = \"NanumSquare\")\n}\n\n\n\n수집한 뉴스에 대해서 워드클라우드를 그려 봅니다.\n\n\nlibrary(bitReport)\n\n#날짜 기준 뉴스\nnews_worldcup_date %>% \n  create_wordcloud(remove_n = 20, min_freq = 2)\n#유사도 기준 뉴스\nnews_worldcup_sim %>% \n  create_wordcloud(remove_n = 20, min_freq = 2)\n\n\n\n정규표현식의 이해\n패턴 검색\n유사도 정렬 기준으로 수집한 뉴스 중에서 선수와 감독의 이름이 포함된\n기사의 건수를 계산하고 각각의 기사에서 해당 선수위 감독의 이름이 몇 번\n등장하는지 계산합니다.\n\n\npersons <- c(\"벤투\", \"손흥민\", \"조규성\", \"이강인\", \"호날두\", \"메시\")\n\npersons %>% \n  purrr::map_int(\n    function(x) {\n      news_worldcup_sim %>% \n        filter(stringr::str_detect(description_text, x)) %>% \n        tally() %>% \n        pull()\n    }\n  )\n\n\n[1]  60  62   0   0   4 182\n\npersons <- c(\"벤투\", \"손흥민\", \"조규성\", \"이강인\", \"호날두\", \"메시\")\n\npersons %>% \n  purrr::map_dbl(\n    function(x) {\n      news_worldcup_sim %>% \n        filter(stringr::str_detect(description_text, x)) %>% \n        mutate(n_talk = stringr::str_count(description_text, x)) %>% \n        summarise(n_avg = mean(n_talk, na.rm = TRUE)) %>% \n        pull()\n    }\n  )\n\n\n[1] 1.166667 1.516129      NaN      NaN 1.000000 1.461538\n\n##Document Term Matrix의 이해 ###DTM 생성하기\n유사도 정렬 기준 뉴스의 Term Frequency 기반의 DTM과 TF-IDF 기반의\nDTM을 생성합니다.\n뉴스 데이터는 문서 아이디로 사용할 변수가 없기 때문에 아이디를\n만듦니다.\n\n\nnews_worldcup_sim <- news_worldcup_sim %>% mutate(id = row_number())\n\n\n\n인명인 고유명사도 함께 추출한 DTM을 만들기 위해서\nunnest_noun_ngrams() 함수의 type 인수값에 “noun2”를 사용합니다.\n\n\nlibrary(tidyverse)\nlibrary(bitTA)\nlibrary(tidytext)\nlibrary(tm)\n\ndtm_tf <- news_worldcup_sim %>% \n  unnest_noun_ngrams(term, description_text, n = 1, type = \"noun2\") %>% \n  filter(!str_detect(term, \"[[a-zA-Z]]+\")) %>%  \n  count(id, term, sort = TRUE) %>% \n  cast_dtm(id, term, n)\n\ntm::inspect(dtm_tf)\n\n\n<<DocumentTermMatrix (documents: 1000, terms: 687)>>\nNon-/sparse entries: 20359/666641\nSparsity           : 97%\nMaximal term length: 6\nWeighting          : term frequency (tf)\nSample             :\n     Terms\nDocs  결승 년 모로코 월드컵 일 축구 카타르 팀 프랑스 한국\n  125    0  0      0      2  2    0      0  0      0    0\n  152    0  1      1      3  1    0      2  0      1    1\n  224    0  0      0      2  2    0      0  0      0    0\n  251    0  1      1      3  1    0      2  0      1    1\n  26     0  0      0      2  2    0      0  0      0    0\n  323    0  0      0      2  2    0      0  0      0    0\n  350    0  1      1      3  1    0      2  0      1    1\n  422    0  0      0      2  2    0      0  0      0    0\n  449    0  1      1      3  1    0      2  0      1    1\n  53     0  1      1      3  1    0      2  0      1    1\n\n#TF-IDF 기반의 DTM\n\ndtm_tfidf <- news_worldcup_sim %>% \n  unnest_noun_ngrams(term, description_text, n = 1, type = \"noun2\") %>% \n  filter(!str_detect(term, \"[[a-zA-Z]]+\")) %>%  \n  count(id, term, sort = TRUE) %>% \n  cast_dtm(id, term, n, weighting = tm::weightTfIdf)\n\ntm::inspect(dtm_tfidf)\n\n\n<<DocumentTermMatrix (documents: 1000, terms: 687)>>\nNon-/sparse entries: 20359/666641\nSparsity           : 97%\nMaximal term length: 6\nWeighting          : term frequency - inverse document frequency (normalized) (tf-idf)\nSample             :\n     Terms\nDocs  결승 년 대표 메시 모로코 아르헨티나 우승 팀 프랑스 한국\n  300    0  0    0    0      0          0    0  0      0    0\n  399    0  0    0    0      0          0    0  0      0    0\n  498    0  0    0    0      0          0    0  0      0    0\n  597    0  0    0    0      0          0    0  0      0    0\n  696    0  0    0    0      0          0    0  0      0    0\n  795    0  0    0    0      0          0    0  0      0    0\n  894    0  0    0    0      0          0    0  0      0    0\n  900    0  0    0    0      0          0    0  0      0    0\n  993    0  0    0    0      0          0    0  0      0    0\n  999    0  0    0    0      0          0    0  0      0    0\n\nCorrelation Analysis\n각각의 선수와 감독별로 상관계수가 0.4 이상인 단어를 추출해봅니다.\nTerm Frequency\n\n\npersons <- c(\"벤투\", \"손흥민\", \"조규성\", \"이강인\", \"호날두\", \"메시\")\n\npersons %>% \n  purrr::map(\n    function(x) tm::findAssocs(dtm_tf, terms = x, corlimit = 0.4)\n  )\n\n\n[[1]]\n[[1]]$벤투\n파울루   개월   부임   생활   직후 마침표   감독   과업   조국     간 \n  0.86   0.82   0.82   0.82   0.82   0.71   0.68   0.57   0.49   0.46 \n  달성 \n  0.46 \n\n\n[[2]]\n[[2]]$손흥민\n      토트넘         얼굴     잉글리시         출장 프리미어리그 \n        0.72         0.50         0.50         0.50         0.50 \n      보호대         부친           손       손웅정     아카데미 \n        0.50         0.50         0.50         0.50         0.50 \n        안면         입성         착용         공동       마스크 \n        0.50         0.50         0.50         0.50         0.50 \n        막판       빅리그         폭풍       득점왕         투호 \n        0.50         0.50         0.50         0.43         0.41 \n\n\n[[3]]\n[[3]]$조규성\nnumeric(0)\n\n\n[[4]]\n[[4]]$이강인\nnumeric(0)\n\n\n[[5]]\n[[5]]$호날두\n    결별       드     맨유 맨체스터       몸     무적     상태 \n     1.0      1.0      1.0      1.0      1.0      1.0      1.0 \n    신세 유나이티     유지 잉글랜드     좌절 \n     1.0      1.0      1.0      1.0      0.4 \n\n\n[[6]]\n[[6]]$메시\n    리오넬 아르헨티나     마지막         꿈       생애       목표 \n      0.81       0.57       0.56       0.51       0.44       0.41 \n      기록     맹활약 \n      0.41       0.41 \n\n연관분석\nBinary Term Frequency 기반\nDTM 생성\n\n\ndtm_bin_tf <- news_worldcup_sim %>% \n  unnest_noun_ngrams(term, description_text, n = 1, type = \"noun2\") %>% \n  filter(!str_detect(term, \"[[a-zA-Z]]+\")) %>%  \n  count(id, term, sort = TRUE) %>% \n  cast_dtm(id, term, n, weighting = tm::weightBin)\n\n\n\n불용어 제거\n상위 50위인 단어를 불용어로 처리하여 제거합니다.\n\n\nstop_words <- dtm_bin_tf %>% \n  apply(2, sum) %>% \n  sort(decreasing = TRUE) %>% \n  \"[\"(1:30) %>% \n  names()\nstop_words\n\n\n [1] \"월드컵\"       \"카타르\"       \"일\"           \"프랑스\"      \n [5] \"한국\"         \"팀\"           \"축구\"         \"결승\"        \n [9] \"시간\"         \"모로코\"       \"우승\"         \"년\"          \n[13] \"진출\"         \"대표\"         \"아르헨티나\"   \"준결승전\"    \n[17] \"번\"           \"카타르월드컵\" \"메시\"         \"강\"          \n[21] \"스타디움\"     \"선수\"         \"대회\"         \"알코르\"      \n[25] \"결승전\"       \"국가\"         \"국제축구연맹\" \"러시아\"      \n[29] \"만\"           \"전\"          \n\ndtm_bin_tf <- news_worldcup_sim %>% \n  unnest_noun_ngrams(term, description_text, n = 1, type = \"noun2\") %>% \n  filter(!term %in% stop_words) %>% \n  filter(!str_detect(term, \"[[a-zA-Z]]+|[[0-9]]+\")) %>%  \n  count(id, term, sort = TRUE) %>% \n  cast_dtm(id, term, n, weighting = tm::weightBin)\n\n\n\nTransactions 생성하기\n\n\nlibrary(\"arules\")\n\ntrans <- as(dtm_bin_tf %>% as.matrix(), \"transactions\")\ntrans\n\n\ntransactions in sparse format with\n 1000 transactions (rows) and\n 655 items (columns)\n\nsummary(trans)\n\n\ntransactions as itemMatrix in sparse format with\n 1000 rows (elements/itemsets/transactions) and\n 655 columns (items) and a density of 0.01803664 \n\nmost frequent items:\n   승리    경기  바이트      알    이번 (Other) \n    113     104     100     100      99   11298 \n\nelement (itemset/transaction) length distribution:\nsizes\n  2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18 \n 20   7  10  10  37  10 100 103  70 111  75  61 147  99  60  23  27 \n 19  22  24 \n 10  10  10 \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   2.00    9.00   12.00   11.81   14.00   24.00 \n\nincludes extended item information - examples:\n  labels\n1     명\n2     홀\n3 오현규\n\nincludes extended transaction information - examples:\n  transactionID\n1             1\n2            26\n3            35\n\n연관규칙 생성하기\n\n\nrules <- apriori(trans, parameter = list(support = 0.05, conf = 0.6, target = \"rules\"))\n\n\nApriori\n\nParameter specification:\n confidence minval smax arem  aval originalSupport maxtime support\n        0.6    0.1    1 none FALSE            TRUE       5    0.05\n minlen maxlen target  ext\n      1     10  rules TRUE\n\nAlgorithmic control:\n filter tree heap memopt load sort verbose\n    0.1 TRUE TRUE  FALSE TRUE    2    TRUE\n\nAbsolute minimum support count: 50 \n\nset item appearances ...[0 item(s)] done [0.00s].\nset transactions ...[655 item(s), 1000 transaction(s)] done [0.00s].\nsorting and recoding items ... [50 item(s)] done [0.00s].\ncreating transaction tree ... done [0.00s].\nchecking subsets of size 1 2 3 done [0.00s].\nwriting ... [51 rule(s)] done [0.00s].\ncreating S4 object  ... done [0.00s].\n\nsummary(rules)\n\n\nset of 51 rules\n\nrule length distribution (lhs + rhs):sizes\n 2  3 \n39 12 \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  2.000   2.000   2.000   2.235   2.000   3.000 \n\nsummary of quality measures:\n    support          confidence        coverage      \n Min.   :0.05000   Min.   :0.6250   Min.   :0.05000  \n 1st Qu.:0.05000   1st Qu.:0.7143   1st Qu.:0.05000  \n Median :0.05000   Median :0.8333   Median :0.06000  \n Mean   :0.05388   Mean   :0.8426   Mean   :0.06573  \n 3rd Qu.:0.05000   3rd Qu.:1.0000   3rd Qu.:0.07950  \n Max.   :0.08000   Max.   :1.0000   Max.   :0.10000  \n      lift            count      \n Min.   : 5.531   Min.   :50.00  \n 1st Qu.:10.550   1st Qu.:50.00  \n Median :12.500   Median :50.00  \n Mean   :12.503   Mean   :53.88  \n 3rd Qu.:13.438   3rd Qu.:50.00  \n Max.   :20.000   Max.   :80.00  \n\nmining info:\n  data ntransactions support confidence\n trans          1000    0.05        0.6\n                                                                                  call\n apriori(data = trans, parameter = list(support = 0.05, conf = 0.6, target = \"rules\"))\n\narules::inspect(rules[1:5])\n\n\n    lhs         rhs      support confidence coverage lift     count\n[1] {계단}   => {통산}   0.067   1.0000000  0.067    12.98701 67   \n[2] {통산}   => {계단}   0.067   0.8701299  0.077    12.98701 67   \n[3] {딩}     => {디펜}   0.050   1.0000000  0.050    20.00000 50   \n[4] {디펜}   => {딩}     0.050   1.0000000  0.050    20.00000 50   \n[5] {인터뷰} => {오현규} 0.050   1.0000000  0.050    12.50000 50   \n\n연관규칙 시각화하기\n\n\nlibrary(\"arulesViz\")\n\nplot(rules)\n\n\n\nrule2 <- sort(rules, by = \"confidence\")\ninspect(head(rule2, n = 10))\n\n\n     lhs                 rhs          support confidence coverage\n[1]  {계단}           => {통산}       0.067   1          0.067   \n[2]  {딩}             => {디펜}       0.050   1          0.050   \n[3]  {디펜}           => {딩}         0.050   1          0.050   \n[4]  {인터뷰}         => {오현규}     0.050   1          0.050   \n[5]  {테}             => {에르난데스} 0.050   1          0.050   \n[6]  {테}             => {선제골}     0.050   1          0.050   \n[7]  {수원}           => {오현규}     0.050   1          0.050   \n[8]  {바}             => {페}         0.079   1          0.079   \n[9]  {페}             => {바}         0.079   1          0.079   \n[10] {에르난데스, 테} => {선제골}     0.050   1          0.050   \n     lift     count\n[1]  12.98701 67   \n[2]  20.00000 50   \n[3]  20.00000 50   \n[4]  12.50000 50   \n[5]  16.66667 50   \n[6]  16.66667 50   \n[7]  12.50000 50   \n[8]  12.65823 79   \n[9]  12.65823 79   \n[10] 16.66667 50   \n\nplot(rules, method = \"grouped\")\n\n\n\nplot(rules, method = \"graph\")\n\n\n\n\n단어의 계층적 군집분석\n희박 단어의 제거\n\n\ndim(dtm_bin_tf)\n\n\n[1] 1000  655\n\ncompact_bin <- tm::removeSparseTerms(dtm_bin_tf, sparse = 0.985) %>%\n  as.matrix(compact_bin)\n\ndim(compact_bin)\n\n\n[1] 1000  217\n\n비상사도 행렬 생성\n\n\nmat <- t(compact_bin)\n\ndist_matrix <- dist(scale(mat))\n\n\n\nClustering\n\n\nfit <- hclust(dist_matrix, method = \"ward.D\")\nfit\n\n\n\nCall:\nhclust(d = dist_matrix, method = \"ward.D\")\n\nCluster method   : ward.D \nDistance         : euclidean \nNumber of objects: 217 \n\n군집 개수 선정 및 시각화\nk개 군집을 나눕니다.\n\n\nk <- 6\n\nplot(fit)\ncluster_list <- rect.hclust(fit, k = k)\n\n\n\n\n군집의 해석\nk개 클러스터를 구성하는 단어들의 목록을 조회합니다.\n\n\nk %>% \n  seq() %>% \n  purrr::map(\n    function(x) {\n      cluster_list[[x]]\n    }\n  )\n\n\n[[1]]\n        분 에르난데스       전반         니       무아     선제골 \n        15         37        148        158        159        160 \n      쐐기         콜         테       후반       랜달 \n       161        162        163        164        201 \n\n[[2]]\n계단 통산 \n  99  100 \n\n[[3]]\n    오현규       예비         저       수원         등       번호 \n         2         14         46         88        142        144 \n    인터뷰 뉴스데스크         뒷       삼성     이야기       순간 \n       145        151        153        154        156        166 \n      아무 \n       167 \n\n[[4]]\n      명     기자     불참     훈련     현지   김민재     심판 \n       1        3        7        8        9       10       11 \n    주심 포르투갈       뒤       월     취재   손흥민     벤투 \n      12       16       19       22       23       24       25 \n      후     차례   폴란드     방송     매체     활약   득점왕 \n      27       28       29       33       34       35       39 \n    미국   특파원     나라     주장     협회     리그       중 \n      41       44       45       47       48       50       56 \n    출전   맞대결       위     조국 프로축구   베이트     오전 \n      57       58       63       64       65       66       68 \n  나폴리       말     새벽     소속       간     매치   우승컵 \n      69       70       72       73       75       78       79 \n    개막     동행     멤버     보름       원   토트넘   파울루 \n      84       85       86       87       89       90       91 \n      점     제압       차     쾌거     소식     여정     남부 \n      95       96       97       98      101      102      104 \n몽펠리에     발생     사고     사망       세     소년     때문 \n     105      106      107      108      109      110      115 \n    주목   경기력     뉴스     보도     상대     영광     월드 \n     117      118      119      120      121      122      123 \n    패배     공항     국제   수비수 이탈리아     이후     인천 \n     124      125      126      127      128      129      130 \n    출국     공개     기사     내용     모습     서울     요약 \n     131      132      133      134      135      136      137 \n  테일러     후보     귀국       그     마음     투호     공격 \n     138      139      140      141      143      146      147 \n      회 대한민국   엔트리     최종     종료     무대     일부 \n     149      152      155      157      165      172      173 \n  지난달       팬     달성     남자     여자   올림픽     도움 \n     174      175      176      179      180      181      182 \n    테오     세계     스타     과업     완승     최근   경기장 \n     183      185      186      188      190      191      192 \n    실리   공격수     감격     공식   가운데     거리     대형 \n     193      194      195      196      197      198      199 \n    사진       외   아시아   취재진     자신     코르     이상 \n     200      204      207      208      210      211      212 \n    기록     생애     오후 \n     213      214      217 \n\n[[5]]\n챔피언   돌풍   디펜     딩 \n    21     80     81     82 \n\n[[6]]\n        강전         이번         유럽         경기           바 \n           4            5            6           13           17 \n          페         감독           수         사상       루사일 \n          18           20           26           30           31 \n          것       브라질           골   크로아티아       준결승 \n          32           36           38           40           42 \n          때         동료       마지막     생제르맹         파리 \n          43           49           51           52           53 \n        영국         좌절           시         시각         역대 \n          54           55           59           60           61 \n        성사         승리         부상         투혼         관심 \n          62           67           71           74           76 \n        대결         남미       바이트           알         연속 \n          77           83           92           93           94 \n        이하           대         도전         연패           이 \n         103          111          112          113          114 \n        역사         처음         데샹         디디       리오넬 \n         116          150          168          169          170 \n      킬리안         이날         기대         목표         최고 \n         171          177          178          184          187 \n    알바레스 러시아월드컵           신         대륙     아프리카 \n         189          202          203          205          206 \n        본선           꿈       맹활약 \n         209          215          216 \n\n기사의 계층적 군집분석\n비상사도 행렬 생성\n\n\nmat <- compact_bin\n\ndist_matrix <- dist(scale(mat))\n\n\n\nClustering\n\n\nfit <- hclust(dist_matrix, method = \"ward.D\")\nfit\n\n\n\nCall:\nhclust(d = dist_matrix, method = \"ward.D\")\n\nCluster method   : ward.D \nDistance         : euclidean \nNumber of objects: 1000 \n\n군집 개수 선정 및 시각화\n\n\nk <- 6\n\nplot(fit)\ncluster_list <- rect.hclust(fit, k = k)\n\n\n\n\n군집의 해석\n군집별 기사 ID를 추출하고 기사의 개수를 조회합니다.\n\n\nclusters <- k %>% \n  seq() %>% \n  purrr::map(\n    function(x) {\n      cluster_list[[x]]\n    }\n  )\n# 기사의 개수\nclusters %>% \n  purrr::map_int(length)\n\n\n[1]  30  70 841  20  20  19\n\n기사 군집 1\n20건 선별 조회 및 워드클라우드 그리기\n\n\nnews_worldcup_sim %>% \n  filter(id %in% clusters[[1]]) %>% \n  select(title_text) %>% \n  head(n = 20)\n\n\n                                                         title_text\n1               월드컵 음바페 경기서 패한 절친 하키미와 뜨거운 포옹\n2       손흥민 아직도 월드클래스 아냐 월드컵 끝나도 단호한 손흥민父\n3             월드컵 승부차기 그 살벌한 카타르시스장환수의 수數포츠\n4                축구의 신 메시 마지막 꿈 월드컵 우승 한걸음 남았다\n5        플레이 볼 가슴에 세 번째 별을 달 그대 그들의 월드컵 이야기\n6   월드컵 음바페와 하키미 진한 포옹으로 이민 2세대 절친대결 마무리\n7        포상금 못받은 예비 오현규 월드컵 멤버들 사비 모아 챙겨줬다\n8         월드컵 메시 1골 1도움아르헨티나 8년 만에 월드컵 결승 진출\n9      월드컵 돌아가는 김민재의 소신발언유럽파 많은 일본이 부럽네요\n10                      월드컵 골키퍼 등번호는 항상 1번인가요궁즉답\n11                    축구의 신 메시의 아픈 손 월드컵첫 우승에 성큼\n12               월드컵 프랑스 모로코 20 제압아르헨티나와 결승 격돌\n13    벤투 대신 퇴장설 사실로컬튜쇼 김진수송민규 월드컵 후일담 전해\n14                    프랑스 돌풍 모로코 2대 0 제압월드컵 결승 진출\n15                       월드컵 축구 대표팀 기념관 된 대통령실 로비\n16                 카타르월드컵 M의 대결 성사메시vs음바페 결승 격돌\n17      월드컵 음바페의 프랑스 메시의 아르헨티나와 결승 매치업 성사\n18                   메시 vs 음바페카타르 월드컵 결승은 신들의 전쟁\n19 월드컵 프랑스 결승행 선방쇼 요리스 메시 앞세운 아르헨도 요리할까\n20           월드컵 프랑스 모로코 돌풍 잠재웠다메시와 결승서 대격돌\n\n# 워드클라우드\nnews_worldcup_sim %>% \n  filter(id %in% clusters[[1]]) %>% \n  unnest_noun_ngrams(term, description_text, n = 1) %>% \n  filter(!str_detect(term, \"[[a-zA-Z]]+|[[0-9]]+\")) %>%  \n  count(term, sort = TRUE) %>% \n  filter(nchar(term) > 1) %>%   \n  filter(row_number() >= 15) %>% \n  wordcloud2::wordcloud2(fontFamily = \"NanumSquare\")\n\n\n\n\nTopic 분석\n기사의 TF 기반의 DTM으로 Topic 분석을 수행합니다.\n희박 단어의 제거\n\n\ncompact_tf <- tm::removeSparseTerms(dtm_tf, sparse = 0.98) %>%\n  as.matrix()\n\ndim(compact_tf)\n\n\n[1] 1000  177\n\nOTF 계산\n\n\notf <- apply(compact_tf, 2, sum) %>% \n  sort(decreasing = TRUE) %>% \n  names()\n\n\n\n불용어 제거\nOverall Term Frequency 상위 15개 단어를 불용어로 간주하여\n제거합니다.\n\n\nstop_word <- otf[1:20]\nstop_word\n\n\n [1] \"월드컵\"     \"카타르\"     \"프랑스\"     \"일\"         \"팀\"        \n [6] \"한국\"       \"모로코\"     \"결승\"       \"축구\"       \"년\"        \n[11] \"시간\"       \"우승\"       \"아르헨티나\" \"대표\"       \"메시\"      \n[16] \"진출\"       \"준결승전\"   \"강\"         \"선수\"       \"번\"        \n\ncompact_tf2 <- compact_tf[, !colnames(compact_tf) %in% stop_word] \ndim(compact_tf2)\n\n\n[1] 1000  157\n\n불용어 제거\n\n\ncompact_tf2 %>% \n  apply(2, sum) \n\n\n          명       오현규         기자       결승전         강전 \n          43          140           78          189           94 \n          만         이번         유럽         대회         현지 \n         122          102           59          179           70 \n      김민재           전         심판         주심         경기 \n          46          135           50           50          134 \n        예비           분     포르투갈           바           페 \n          72          118           34           89           89 \n          뒤         국가         감독       챔피언           월 \n          38          143          110           60           60 \n      손흥민         벤투           수           후         차례 \n          94           40           93           44           50 \n        사상       루사일           것         방송         매체 \n          50           80           88           38           40 \n        활약       브라질   에르난데스           골   크로아티아 \n          50           40           70           92           34 \n        미국       준결승           때       러시아       특파원 \n          50           32           31          128           21 \n          저         주장         협회         동료         리그 \n          32           32           22           29           49 \n      마지막     생제르맹         파리         영국         좌절 \n          80           26           52           37           24 \n          중         출전       맞대결           시         시각 \n          29           44           61           80           42 \n        역대 카타르월드컵 국제축구연맹         성사           위 \n          55          193          131           55           36 \n        조국       베이트     스타디움         승리       알코르 \n          26           27          167          113          137 \n        오전           말         부상         새벽         소속 \n          27           24           38           38           46 \n        투혼           간         관심         대결         돌풍 \n          28           29           29           39           60 \n        디펜           딩         남미         개막         멤버 \n          50           50           30           30           30 \n        수원       토트넘       바이트           알         연속 \n          50           30          100          100           60 \n          점         쾌거         계단         통산         소식 \n          30           30           67           77           30 \n        이하         사망           세         소년           대 \n          50           35           30           26           50 \n        도전         연패           이         역사         뉴스 \n          71           40           70           60           30 \n    이탈리아         이후         기사         내용         요약 \n          29           40           21           31           21 \n        후보           그           등         마음         번호 \n          30           30           70           30           60 \n      인터뷰         투호         공격         전반           회 \n          50           30           21           80           40 \n        처음   뉴스데스크     대한민국           뒷         삼성 \n          30           40           30           50           40 \n      엔트리       이야기         최종           니         무아 \n          50           40           40           30           30 \n      선제골         쐐기           콜           테         후반 \n          60           30           30           50           40 \n        데샹         디디       리오넬       킬리안         무대 \n          30           30           84           30           60 \n          팬         달성         여자         도움         세계 \n          41           30           30           24           40 \n        스타       경기장       공격수         공식       가운데 \n          21           40           30           40           25 \n        사진 러시아월드컵           신       아시아         자신 \n          27           30           30           28           40 \n        생애           꿈 \n          23           30 \n\nlibrary(\"topicmodels\")\n\nk <- 2:10\n\nmodels <- k %>% \n  purrr::map(\n    function(x) {\n      topicmodels::LDA(compact_tf2, k = x, control = list(seed = 123))\n    }\n  )\n\n\n\nTopic 개수 구하기\n\n\n# LOG-LIKELIHOOD\nlog_ikelihood <- models %>% \n  purrr::map_dbl(logLik)\nlog_ikelihood\n\n\n[1] -41873.69 -38543.03 -37632.98 -37383.98 -36929.48 -36374.93\n[7] -35716.27 -35545.06 -35318.04\n\nwhich.max(log_ikelihood)\n\n\n[1] 9\n\n#ALPHA\nalpha <- models %>% \n  purrr::map_dbl(slot, \"alpha\")\nalpha\n\n\n[1] 38.62717433  0.09819337  0.09802429  0.10374254  0.10293525\n[6]  0.08909183  0.07118032  0.07680259  0.07187277\n\nwhich.min(alpha)\n\n\n[1] 7\n\nTop beta 단어의 시각화\n\n\nprob <- tidytext::tidy(models[[9]], matrix = \"beta\")\nprob\n\n\n# A tibble: 1,570 × 3\n   topic term       beta\n   <int> <chr>     <dbl>\n 1     1 명    1.12e-138\n 2     2 명    5.90e-  2\n 3     3 명    3.64e- 32\n 4     4 명    2.27e- 26\n 5     5 명    3.24e- 77\n 6     6 명    4.58e- 39\n 7     7 명    8.53e- 31\n 8     8 명    3.19e-191\n 9     9 명    2.96e- 62\n10    10 명    2.77e- 43\n# … with 1,560 more rows\n\ntop_prob <- prob %>% \n  group_by(topic) %>% \n  top_n(10, beta) %>% \n  ungroup() %>% \n  arrange(topic, -beta)\ntop_prob\n\n\n# A tibble: 102 × 3\n   topic term         beta\n   <int> <chr>       <dbl>\n 1     1 분         0.154 \n 2     1 전반       0.104 \n 3     1 에르난데스 0.0913\n 4     1 선제골     0.0782\n 5     1 러시아     0.0665\n 6     1 테         0.0652\n 7     1 이         0.0652\n 8     1 승리       0.0650\n 9     1 후반       0.0522\n10     1 골         0.0415\n# … with 92 more rows\n\ntop_prob %>% \n  mutate(term = reorder(term, beta)) %>% \n  ggplot(aes(x = term,  y = beta, fill = factor(topic))) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~topic, scales = \"free\") +\n  coord_flip()\n\n\n\n\n문서에서의 토픽의 비중\n\n\nnews_gamma <- tidytext::tidy(models[[9]], matrix = \"gamma\") %>% \n  mutate(gamma = gamma * 100)\n\nnews_gamma\n\n\n# A tibble: 10,000 × 3\n   document topic gamma\n   <chr>    <int> <dbl>\n 1 75           1  1.93\n 2 174          1  1.93\n 3 273          1  1.93\n 4 372          1  1.93\n 5 471          1  1.93\n 6 570          1  1.93\n 7 669          1  1.93\n 8 768          1  1.93\n 9 867          1  1.93\n10 966          1  1.93\n# … with 9,990 more rows\n\n토픽이 포함된 문서 조회\n\n\n#토픽1의 주요 단어\nterms(models[[9]], 10)[, 1]\n\n\n [1] \"분\"         \"전반\"       \"에르난데스\" \"선제골\"     \"러시아\"    \n [6] \"테\"         \"이\"         \"승리\"       \"후반\"       \"골\"        \n\n#토픽 1이 95% 이상 포함된 문서 조회\nnews_gamma %>%\n  filter(topic == 1) %>%\n  filter(gamma >= 95) %>%\n  arrange(desc(gamma))\n\n\n# A tibble: 30 × 3\n   document topic gamma\n   <chr>    <int> <dbl>\n 1 33           1  96.1\n 2 132          1  96.1\n 3 231          1  96.1\n 4 330          1  96.1\n 5 429          1  96.1\n 6 529          1  96.1\n 7 628          1  96.1\n 8 727          1  96.1\n 9 826          1  96.1\n10 925          1  96.1\n# … with 20 more rows\n\n# 61번째 기사의 이해\nnews_worldcup_sim %>% \n  filter(id %in% \"61\") %>% \n  select(title_text) %>% \n  pull()\n\n\n[1] \"월드컵 축구 대표팀 기념관 된 대통령실 로비\"\n\nnews_worldcup_sim %>% \n  filter(id %in% \"61\") %>% \n  select(description_text) %>% \n  pull()\n\n\n[1] \"대통령실이 최근 카타르월드컵에서 16강 진출을 이룬 축구 국가대표팀이 윤석열 대통령에게 선물한... 대통령실은 13일 1층 로비에 대표팀 선수들의 사인이 담긴 대형 사진과 대표팀 주장인 손흥민 선수가 월드컵 16강... \"\n\n문서의 토픽 분해\n모든 문서는 토픽들의 복합체입니다. 기사 1을 분해하여 토픽의 비율을\n조해해 봅니다.\n\n\nnews_gamma %>%\n  filter(document %in% \"1\") %>% \n  arrange(desc(gamma)) \n\n\n# A tibble: 10 × 3\n   document topic  gamma\n   <chr>    <int>  <dbl>\n 1 1            2 34.7  \n 2 1            5 17.7  \n 3 1           10 17.7  \n 4 1            7  9.17 \n 5 1            3  9.15 \n 6 1            1  9.14 \n 7 1            9  0.613\n 8 1            4  0.613\n 9 1            6  0.613\n10 1            8  0.613\n\n토픽의 단어 분해\n\n\ntop_prob %>% \n  filter(topic == 6) %>% \n  arrange(desc(beta))  \n\n\n# A tibble: 10 × 3\n   topic term         beta\n   <int> <chr>       <dbl>\n 1     6 오현규     0.150 \n 2     6 예비       0.0772\n 3     6 등         0.0644\n 4     6 번호       0.0644\n 5     6 수원       0.0536\n 6     6 인터뷰     0.0536\n 7     6 뒷         0.0536\n 8     6 뉴스데스크 0.0429\n 9     6 삼성       0.0429\n10     6 이야기     0.0429\n\n이진분류 모형\n패키지 로드하기\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(text2vec)\nlibrary(glmnet)\nlibrary(caret)\nlibrary(bitTA)  \n\n\n\n파생변수 만들기\n연합뉴스 여부\n연합뉴스 기사: 1\n기타 뉴스기사: 0\n\n\n\nnews_worldcup_yna <- news_worldcup_sim %>% \n  mutate(yna_flag = ifelse(stringr::str_detect(originallink, \"www.yna.co.kr\"), 1, 0))\n\nnews_worldcup_yna %>% \n  count(yna_flag) %>% \n  mutate(ratio = n /sum(n) * 100)\n\n\n  yna_flag   n ratio\n1        0 809  80.9\n2        1 191  19.1\n\n불균형 데이터의 언더 샘플링\n\n\nn_yna <- news_worldcup_yna %>% \n  filter(yna_flag == 1) %>% \n  tally() %>% \n  pull()\n\nn_not_yna <- news_worldcup_yna %>% \n  filter(yna_flag == 0) %>% \n  tally() %>% \n  pull()\n\nset.seed(123)\nidx_sample <- sample(seq(n_not_yna), size = n_yna)\n\nsubset_not_yna <- news_worldcup_yna %>% \n  filter(yna_flag == 0) %>% \n  filter(row_number() %in% idx_sample)\n\nsubset_yna <- news_worldcup_yna %>% \n  filter(yna_flag == 1)\n\nnews_sample_yna <- bind_rows(subset_not_yna, subset_yna)\n\nnews_sample_yna %>% \n  count(yna_flag) \n\n\n  yna_flag   n\n1        0 191\n2        1 191\n\n데이터셋 분리\n\n\nset.seed(123)\nnews_split <- initial_split(news_sample_yna, strata = yna_flag)\n\ntrain <- rsample::training(news_split)\ntest <- rsample::testing(news_split)\n\ndim(train)\n\n\n[1] 286   9\n\ndim(test)\n\n\n[1] 96  9\n\ntrain %>% \n  count(yna_flag)\n\n\n  yna_flag   n\n1        0 143\n2        1 143\n\ntest %>% \n  count(yna_flag)\n\n\n  yna_flag  n\n1        0 48\n2        1 48\n\ntokenize 반복기 정의\n\n\n# 일반명사 단위로 토큰을 생성\ntoken_fun <- bitTA::morpho_mecab\n\nit_train <- itoken_parallel(train$description_text, \n                   tokenizer = token_fun, \n                   ids = train$id, \n                   progressbar = FALSE)\n\nit_test <- itoken_parallel(test$description_text, \n                  tokenizer = token_fun, \n                  ids = test$id, \n                  progressbar = FALSE)\n\n\n\nFrequency 기반의 DTM 생성\n\n\n# VOCABULARY 생성\nlibrary(doParallel)\n\nnc <- parallel::detectCores()\nregisterDoParallel(cores = nc)\n\nvocab <- create_vocabulary(it_train)\n\ntail(vocab, n = 10)\n\n\nNumber of docs: 286 \n0 stopwords:  ... \nngram_min = 1; ngram_max = 1 \nVocabulary: \n          term term_count doc_count\n 1: 아르헨티나         91        76\n 2:       우승         92        72\n 3:       축구         92        89\n 4:         팀        103        83\n 5:       시간        122       119\n 6:       결승        123       105\n 7:     모로코        137        95\n 8:     프랑스        264       156\n 9:     카타르        300       212\n10:     월드컵        563       280\n\n# DOCUMENT TERM MATRIX 생성하기\nvectorizer <-  vocab_vectorizer(vocab)\n\ndtm_train_tf <- text2vec::create_dtm(it_train, vectorizer)\ndim(dtm_train_tf)\n\n\n[1] 286 511\n\ndtm_test_tf <- text2vec::create_dtm(it_test, vectorizer)\ndim(dtm_test_tf)\n\n\n[1]  96 511\n\nN-Grams 기반의 DTM 생성\n\n\n# VOCABULARY 생성\nvocab_bigram <- create_vocabulary(it_train, ngram = c(1L, 2L))\ndim(vocab_bigram)\n\n\n[1] 1639    3\n\n# PRUNE VOCABULARY\nvocab_bigram <- vocab_bigram %>% \n  prune_vocabulary(term_count_min = 10,\n                   doc_proportion_max = 0.5)\ndim(vocab_bigram)\n\n\n[1] 167   3\n\n# DOCUMENTS TERM MATRIX 생성\nvectorizer_bigram <- vocab_vectorizer(vocab_bigram)\n\ndtm_train_bigram <- create_dtm(it_train, vectorizer_bigram)\ndim(dtm_train_bigram)\n\n\n[1] 286 167\n\ndtm_test_bigram  <- create_dtm(it_test, vectorizer_bigram)\ndim(dtm_test_bigram)\n\n\n[1]  96 167\n\nTF-IDF 기반의 DTM 생성\n\n\ntfidf <- TfIdf$new()\n\ndtm_train_tfidf <- fit_transform(dtm_train_tf, tfidf)\ndtm_test_tfidf <- fit_transform(dtm_test_tf, tfidf) \n\n\n\nDTM의 크기 비교\n\n\ndim(dtm_train_tf)\n\n\n[1] 286 511\n\ndim(dtm_train_bigram)\n\n\n[1] 286 167\n\ndim(dtm_train_tfidf) \n\n\n[1] 286 511\n\nFrequency 기반 모델링\n\n\nNFOLDS <- 10\n\nclassifier_tf <- cv.glmnet(x = dtm_train_tf, y = train$yna_flag, \n                           family = \"binomial\",\n                           alpha = 1,\n                           parallel = TRUE, \n                           keep = TRUE) \n\n\n\n모델의 이해\n\n\nlibrary(broom)\n\ncoefs_tf <- classifier_tf$glmnet.fit %>%\n  tidy() %>%\n  filter(lambda == classifier_tf$lambda.1se)\ncoefs_tf \n\n\n# A tibble: 83 × 5\n   term         step  estimate  lambda dev.ratio\n   <chr>       <dbl>     <dbl>   <dbl>     <dbl>\n 1 (Intercept)    74 -2.57e+ 0 0.00686     0.937\n 2 감동           74 -1.25e+ 0 0.00686     0.937\n 3 결국           74 -1.00e- 1 0.00686     0.937\n 4 관중석         74 -9.92e- 1 0.00686     0.937\n 5 류             74 -1.20e- 2 0.00686     0.937\n 6 예고           74 -1.15e- 2 0.00686     0.937\n 7 예지           74 -3.45e-15 0.00686     0.937\n 8 툽             74 -1.19e- 1 0.00686     0.937\n 9 포착           74 -1.61e- 2 0.00686     0.937\n10 현재           74 -3.27e- 3 0.00686     0.937\n# … with 73 more rows\n\ncoefs_tf %>%\n  group_by(estimate > 0) %>%\n  top_n(10, abs(estimate)) %>%\n  ungroup() %>%\n  ggplot(aes(fct_reorder(term, estimate), estimate, fill = estimate > 0)) +\n  geom_col(alpha = 0.8, show.legend = FALSE) +\n  coord_flip() +\n  labs(\n    x = NULL,\n    title = \"예측에 영향을 주는 모델의 계수들 with TF\",\n    subtitle = \"네이버 월드컵 관련 뉴스\"\n  )\n\n\n\n\n모델의 평가\n\n\n# 정오분류행렬\nnews_tf <- predict(classifier_tf, dtm_test_tf, type = 'class')\ncm_tf <- confusionMatrix(factor(test$yna_flag), factor(news_tf), positive = \"1\")\ncm_tf\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  0  1\n         0 46  2\n         1  0 48\n                                          \n               Accuracy : 0.9792          \n                 95% CI : (0.9268, 0.9975)\n    No Information Rate : 0.5208          \n    P-Value [Acc > NIR] : <2e-16          \n                                          \n                  Kappa : 0.9583          \n                                          \n Mcnemar's Test P-Value : 0.4795          \n                                          \n            Sensitivity : 0.9600          \n            Specificity : 1.0000          \n         Pos Pred Value : 1.0000          \n         Neg Pred Value : 0.9583          \n             Prevalence : 0.5208          \n         Detection Rate : 0.5000          \n   Detection Prevalence : 0.5000          \n      Balanced Accuracy : 0.9800          \n                                          \n       'Positive' Class : 1               \n                                          \n\n# ROC 커브\nlibrary(\"pROC\")\n\npredictions <- predict(classifier_tf, dtm_test_tf, type = 'response')\nroc_tf <- pROC::roc(test$yna_flag, predictions)\n\npROC::auc(roc_tf)\n\n\nArea under the curve: 1\n\nplot(roc_tf)\n\n\n\nidx <- predictions %>% \n  which.max()\n\npredictions[idx]\n\n\n[1] 0.9832928\n\ntest[idx, \"description_text\"]\n\n\n[1] \"카타르 월드컵 준결승전에서 프랑스를 상대로 잘 싸웠지만 아쉽게 졌다며 패배 소식을 보도했다. 현지 영문 일간 월드뉴스는 14일(현지시간) 프랑스전에서 눈부신 경기력을 보여줬지만, 모로코의 영광스러운 월드컵... \"\n\nidx <- predictions %>% \n  which.min()\n\npredictions[idx]\n\n\n[1] 0.001861351\n\ntest[idx, \"description_text\"]\n\n\n[1] \"아르헨티나는 14일(한국시각) 카타르 루사일의 루사일스타디움에서 열린 2022 카타르월드컵 4강전에서... 아르헨티나 축구 역사상 여섯 번째 월드컵 결승이다. 독일(8회)에 이어 역대 2위. 메시를 향한 마음으로 똘똘 뭉친... \"\n\n\n\n\n",
      "last_modified": "2022-12-16T11:38:57+09:00"
    },
    {
      "path": "classifier_lasso.html",
      "title": "대통령 연설문 예측",
      "description": "텍스트 분류모형을 개발하고, DTM의 종류별 성능의 차이를 비교해봅니다.\n",
      "author": [
        {
          "name": "김민성",
          "url": "https://minnsung-kim.github.io"
        }
      ],
      "date": "2022-12-16",
      "contents": "\n\nContents\n준비하기\n패키지 로드하기\n\n데이터셋 샘플링\n데이터셋 분리\n\nVectorization\nFrequency 기반의 DTM 생성\ntokenize 반복기 정의\nVocabulary 생성\nDocument Term Matrix\n생성하기\n\nN-Grams 기반의 DTM 생성\nVocabulary 생성\nPrune Vocabulary\nDocuments Term Matrix\n생성\n\nTF-IDF 기반의 DTM 생성\nDTM의 TF-IDF 변환\n\nDTM의 크기 비교\nFrequency 기반 모델링\n모델 생성\n모델의 평가\n\nN-Grams 기반 모델링\n모델 생성\n모델의 평가\n\nTF-IDF 기반의 모델\n모델 생성\n모델의 평가\n\n모델 성능의 비교\n\n준비하기\n패키지 로드하기\n텍스트 분류모델 개발을 위한 패키지를 로드합니다.\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(text2vec)\nlibrary(glmnet)\nlibrary(caret)\nlibrary(bitTA)\nlibrary(doParallel)\n\n\n\n데이터셋 샘플링\ninitial_split(), initial_split(), initial_split() 함수로 원 데이터를\n학습 : 평가 = 70% : 30%로 분리를 수행합니다.\n\n\nset.seed(123)\n president_split <- rsample::initial_split(president_speech, prop = 7/8, strata = president)\npresident_smpl <- rsample::testing(president_split)\n\n\n\n데이터셋 분리\n비로소 모델 개발을 위한 데이터 셋을 분리합니다\ninitial_split(), initial_split(), initial_split() 함수로 원 데이터를\n학습 : 평가 = 70% : 30%로 분리를 수행합니다.\n\n\nset.seed(123)\npresident_split <- initial_split(president_smpl, prop = 0.7, strata = president)\n\ntrain <- rsample::training(president_split)\ntest <- rsample::testing(president_split)\n\n\n\nVectorization\n모델링을 위해서 비정형데이터인 documents 데이터를 vector로 변환해야\n합니다. 이 경우 엄청난 데이터의 증가가 필연적으로 따라옵니다. 그래서\n연산 속도의 개선을 위해서 vectorization 구조로 연산을 해야하기 때문에\nVectorization 연산을 수행하기 위한 구조로 변환해야 합니다. 최종 구조는\nDTM(Document Term Matrix)로 생성합니다.\nFrequency 기반의 DTM 생성\ntokenize 반복기 정의\nitoken_parallel() 함수로 tokenize 반복기를 정의합니다.\n\n\n# 띄어쓰기 단위로 토큰을 생성\n\ntoken_fun <- text2vec::word_tokenizer\n\nit_train <- itoken(train$doc, \n                   tokenizer = token_fun, \n                   ids = train$id, \n                   progressbar = FALSE)\n\nit_test <- itoken(test$doc,\n                  tokenizer = token_fun, \n                  ids = test$id, \n                  progressbar = FALSE)\n\n\n\nVocabulary 생성\n\n\nnc <- parallel::detectCores()\nregisterDoParallel(cores = nc)\n\nvocab <- create_vocabulary(it_train)\n\ntail(vocab, n = 10)\n\n\nNumber of docs: 210 \n0 stopwords:  ... \nngram_min = 1; ngram_max = 1 \nVocabulary: \n        term term_count doc_count\n 1:   그리고        505       147\n 2:       한        505       134\n 3:       그        566       135\n 4:     있는        601       155\n 5:   여러분        607       175\n 6:       이        625       153\n 7:     우리        886       175\n 8:       수        935       167\n 9: 것입니다       1004       180\n10: 있습니다       1383       192\n\nDocument Term Matrix\n생성하기\ndocuments taxonomy 분류 모델을 수행하는 데이터셋은 DTM(Document Term\nMatrix) 구조여야 합니다. 그래서 vocabulary를 DTM으로 변환하는 작업을\n수행합니다. text2vec::create_dtm() 함수를 사용합니다.\n\n\nvectorizer <-  vocab_vectorizer(vocab)\n\ndtm_train_tf <- text2vec::create_dtm(it_train, vectorizer)\ndim(dtm_train_tf)\n\n\n[1]   210 31602\n\ndtm_test_tf <- text2vec::create_dtm(it_test, vectorizer)\ndim(dtm_test_tf)\n\n\n[1]    92 31602\n\nN-Grams 기반의 DTM 생성\nN-grams은 N개의 연속된 terms의 조합을 terms로 간주하여 vocabulary를\n생성하고 이 데이터 기반으로 모델을 생성합니다. 파편화된 terms이 아니기\n때문에 일반적인 vocabulary를 이용한 분석보다는 좀 더 정확하게 문맥을\n파악할 수 있는 장점이 있습니다.\nVocabulary 생성\n\n\nvocab_bigram <- create_vocabulary(it_train, ngram = c(1L, 2L))\ndim(vocab_bigram)\n\n\n[1] 126313      3\n\nPrune Vocabulary\nDocuments의 개수가 증가하거나 Documents의 길이가 증가하면,\nVocabulary의 규모도 증가합니다. 이것은 모델을 생성하는데 많은 컴퓨팅\n리소스를 소모해서 속도가 느려지게 됩니다. 그래서 모델에 영향을 덜 줄 수\n있는 terms를 제거하는 작업이 필요합니다.\n\n\nvocab_bigram <- vocab_bigram %>% \n  prune_vocabulary(term_count_min = 10,\n                   doc_proportion_max = 0.5)\ndim(vocab_bigram)\n\n\n[1] 2046    3\n\nDocuments Term Matrix 생성\n\n\nvectorizer_bigram <- vocab_vectorizer(vocab_bigram)\n\ndtm_train_bigram <- create_dtm(it_train, vectorizer_bigram)\ndim(dtm_train_bigram)\n\n\n[1]  210 2046\n\ndtm_test_bigram  <- create_dtm(it_test, vectorizer_bigram)\ndim(dtm_test_bigram)\n\n\n[1]   92 2046\n\nTF-IDF 기반의 DTM 생성\n대통령 연설문에서는 대부분 “존경하는 국민 여러분”으로 시작할\n것입니다. 그러므로 “존경하는”이라는 term은 모든 연설문에 포함되기 때문에\nterm frequency와 document term frequency가 상당히 클 것입니다. 그러나 이\nterm으로 세명의 전직 대통령의 연설문을 구분하기 어렵습니다. 세명의 전직\n대통령이 즐겨 사용하는 단어이기 때문입니다. 즉, term frequency와\ndocument term frequency가 상당히 큰 terms은 모델 개발에 의미가 없는\nterms인 것입니다.\nTF-IDF는 단일문서, 혹은 소수의 문서에서 의미가 있는 terms의 가중치를\n높이고 대부분의 문서에서 발현하는 terms의 가중치를 줄이는 용도로\n만들어진 측도입니다. 그러므로 DTM에 TF-IDF 변환을 수행하면 모델의 성능이\n개선됩니다.\nText Anaytics에서는 documents의 길이의 차이가 있으면, 상대적으로\n짧거나 긴 documents에서 발현하는 terms들로 인해서 frequency scale에\n왜곡이 있을 수 있습니다. 이 경우에는 표준화를 수행해야 합니다. 그런데\nTF-IDF 변환은 자동으로 표준화가 되기 때문에 표준화의 잇점이 있습니다.\n만약 표준화를 수행하려면, normalize() 함수를 사용하면 됩니다.\nDTM의 TF-IDF 변환\nTfIdf class와 fit_transform() 함수를 이용해서 DTM에 TF-IDF 변환을\n수행합니다.\n\n\ntfidf <- TfIdf$new()\n\ndtm_train_tfidf <- fit_transform(dtm_train_tf, tfidf)\ndtm_test_tfidf <- fit_transform(dtm_test_tf, tfidf) \n\n\n\nDTM의 크기 비교\n세가지 방법으로 만들어진 DTM의 크기를 비교해 봅니다. 비교 결과\nbi-grams으로 만들어진 DTM은 다른 DTM보다 크기가 작은 것을 확인할 수\n있었습니다.\n\n\ndim(dtm_train_tf)\n\n\n[1]   210 31602\n\ndim(dtm_train_bigram)\n\n\n[1]  210 2046\n\ndim(dtm_train_tfidf)\n\n\n[1]   210 31602\n\nFrequency 기반 모델링\n모든 terms을 모델의 독립변수로 사용하려 하기 때문에, terms의 개수가\n독립변수의 개수와 같게 됩니다. 이 경우에는 over-fitting의 이슈가\n발생하므로 이를 해결하기 위해서 over-fitting을 방지해주는 LASSO 모델을\n사용하기로 합니다. 또한 target 변수가 binary가 아닌 3개의 class이기\n때문에 family 함수는 “multinomial”을 지정합니다. 즉, multinomial\nlogistic regression의 알고리즘에 기반한 LASSO 모델을 만듭니다.\nLASSO 모델을 생성하기 위해서는 cv.glmnet() 함수에서 penalty값인\nalpha의 값을 1로 지정해야 LASSO Generalized Linear Model로 모델이\n만들어집니다. alpha의 값이 0이면 Ridge Generalized Linear Model, 0.5이면\nElastic Net Regularized Generalized Linear Model이 생성됩니다.\ntype.measure은 cross-validation을 위한 loss값 계산에 사용하는 측도를\n지원합니다. 일반적으로 binomial family 함수의 경우에는 type.measure\n인수를 AUC(Area Under Curve)인 “auc”를 사용하지만, multinomial family\n함수의 경우에는 이를 사용할 수 없기 때문에 여기서는 “deviance”를\n사용하였습니다. 이 값이 기본값입니다.\n그리고 “auc”를 지정해서 알아서 적당한 측도로 모델을 수행합니다.\n그리고 k-folds cross-validation의 k의 값은 10으로 지정하여, 10-fold\ncross-validation을 수행하여 over-fitting 또한 방지하도록 합니다.\n모델 생성\n\n\nNFOLDS <- 10\n\nclassifier <- cv.glmnet(x = dtm_train_tf, y = train$president, \n                        family = 'multinomial', \n                        alpha = 1,\n                        type.measure = \"deviance\",\n                        nfolds = NFOLDS,\n                        thresh = 0.001,\n                        maxit = 1000,\n                        parallel = TRUE)\n\n\n\n모델의 평가\ntest 데이터로 평가한 결과 Accuracy가 0.7717로 나타났습니다.\n\n\npred_voca <- predict(classifier, dtm_test_tf, type = 'response')[, , 1]\npresident_voca <- apply(pred_voca, 1, \n                        function(x) colnames(pred_voca)[which(max(x) == x)])\n\ncmat_voca <- confusionMatrix(factor(president_voca), factor(test$president))\ncmat_voca\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction 김대중 노무현 이명박\n    김대중     21      0      2\n    노무현      7     25      4\n    이명박      3      5     25\n\nOverall Statistics\n                                          \n               Accuracy : 0.7717          \n                 95% CI : (0.6725, 0.8528)\n    No Information Rate : 0.337           \n    P-Value [Acc > NIR] : < 2e-16         \n                                          \n                  Kappa : 0.6579          \n                                          \n Mcnemar's Test P-Value : 0.06262         \n\nStatistics by Class:\n\n                     Class: 김대중 Class: 노무현 Class: 이명박\nSensitivity                 0.6774        0.8333        0.8065\nSpecificity                 0.9672        0.8226        0.8689\nPos Pred Value              0.9130        0.6944        0.7576\nNeg Pred Value              0.8551        0.9107        0.8983\nPrevalence                  0.3370        0.3261        0.3370\nDetection Rate              0.2283        0.2717        0.2717\nDetection Prevalence        0.2500        0.3913        0.3587\nBalanced Accuracy           0.8223        0.8280        0.8377\n\nN-Grams 기반 모델링\n모델 생성\n\n\nclassifier <- cv.glmnet(x = dtm_train_bigram, y = train$president, \n                        family = 'multinomial', \n                        type.measure = \"deviance\",\n                        alpha = 1,                        \n                        nfolds = NFOLDS,\n                        parallel = TRUE)\n\n\n\n모델의 평가\ntest 데이터로 평가한 결과 Accuracy가 0.7717로 나타났습니다.\n\n\npred_bigram <- predict(classifier, dtm_test_bigram, type = 'response')[, , 1]\n\npresident_bigram <- apply(pred_bigram, 1, \n                          function(x) colnames(pred_bigram)[which(max(x) == x)])\n\ncmat_bigram <- confusionMatrix(factor(president_bigram), factor(test$president))\ncmat_bigram\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction 김대중 노무현 이명박\n    김대중     22      1      1\n    노무현      3     25      5\n    이명박      6      4     25\n\nOverall Statistics\n                                          \n               Accuracy : 0.7826          \n                 95% CI : (0.6844, 0.8619)\n    No Information Rate : 0.337           \n    P-Value [Acc > NIR] : <2e-16          \n                                          \n                  Kappa : 0.674           \n                                          \n Mcnemar's Test P-Value : 0.1966          \n\nStatistics by Class:\n\n                     Class: 김대중 Class: 노무현 Class: 이명박\nSensitivity                 0.7097        0.8333        0.8065\nSpecificity                 0.9672        0.8710        0.8361\nPos Pred Value              0.9167        0.7576        0.7143\nNeg Pred Value              0.8676        0.9153        0.8947\nPrevalence                  0.3370        0.3261        0.3370\nDetection Rate              0.2391        0.2717        0.2717\nDetection Prevalence        0.2609        0.3587        0.3804\nBalanced Accuracy           0.8384        0.8522        0.8213\n\nTF-IDF 기반의 모델\n모델 생성\n\n\nclassifier <- cv.glmnet(x = dtm_train_tfidf, y = train$president, \n                        family = 'multinomial', \n                        nfolds = NFOLDS,\n                        thresh = 1e-3,\n                        maxit = 1e3,\n                        parallel = TRUE)\n\n\n\n모델의 평가\ntest 데이터로 평가한 결과 Accuracy가 0.7935로 나타났습니다.\n\n\npred_tfidf <- predict(classifier, dtm_test_tfidf, type = 'response')[, , 1]\n\npresident_tfidf <- apply(pred_tfidf, 1, \n                         function(x) colnames(pred_tfidf)\n                         [which(max(x) == x)])\n\ncmat_tfidf <- confusionMatrix(factor(president_tfidf), factor(test$president))\ncmat_tfidf\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction 김대중 노무현 이명박\n    김대중     28      7      4\n    노무현      2     20      2\n    이명박      1      3     25\n\nOverall Statistics\n                                          \n               Accuracy : 0.7935          \n                 95% CI : (0.6964, 0.8708)\n    No Information Rate : 0.337           \n    P-Value [Acc > NIR] : <2e-16          \n                                          \n                  Kappa : 0.6899          \n                                          \n Mcnemar's Test P-Value : 0.1888          \n\nStatistics by Class:\n\n                     Class: 김대중 Class: 노무현 Class: 이명박\nSensitivity                 0.9032        0.6667        0.8065\nSpecificity                 0.8197        0.9355        0.9344\nPos Pred Value              0.7179        0.8333        0.8621\nNeg Pred Value              0.9434        0.8529        0.9048\nPrevalence                  0.3370        0.3261        0.3370\nDetection Rate              0.3043        0.2174        0.2717\nDetection Prevalence        0.4239        0.2609        0.3152\nBalanced Accuracy           0.8614        0.8011        0.8704\n\n모델 성능의 비교\n모델 성능 비교결과 TF-IDF > Bigram(Pruned) = Frequency의 순서로\n나타났습니다.\n\n\naccuracy <- rbind(cmat_voca$overall, cmat_bigram$overall, \n                  cmat_tfidf$overall) %>%\n  round(3)\n\ndata.frame(Method = c(\"Frequency\", \"Bigram\", \"TF-IDF\"),\n           accuracy) %>%\n  arrange(desc(Accuracy)) %>%\n  knitr::kable()\n\n\n\nMethod\n\n\nAccuracy\n\n\nKappa\n\n\nAccuracyLower\n\n\nAccuracyUpper\n\n\nAccuracyNull\n\n\nAccuracyPValue\n\n\nMcnemarPValue\n\n\nTF-IDF\n\n\n0.793\n\n\n0.690\n\n\n0.696\n\n\n0.871\n\n\n0.337\n\n\n0\n\n\n0.189\n\n\nBigram\n\n\n0.783\n\n\n0.674\n\n\n0.684\n\n\n0.862\n\n\n0.337\n\n\n0\n\n\n0.197\n\n\nFrequency\n\n\n0.772\n\n\n0.658\n\n\n0.672\n\n\n0.853\n\n\n0.337\n\n\n0\n\n\n0.063\n\n\n\n\n\n",
      "last_modified": "2022-12-16T11:39:08+09:00"
    },
    {
      "path": "create_website.html",
      "title": "웹 사이트 개발하기",
      "description": "“웹 사이트를 개발하는 방법을 간단하게 소개합니다.”\n",
      "author": [
        {
          "name": "김민성",
          "url": "https://minnsung-kim.github.io"
        }
      ],
      "date": "2022-10-01",
      "contents": "\n\nContents\n설정사항\n수정해야할 사항\n웹 사이트 구성 파일\n개별 페이지 구성 정보\n\nData: USArrests\n표(tables) 출력\n플롯(plots) 출력\n\n\n\n\n\n\n들어가기\n이 웹 사이트는 예제를 위해서 만든 간단한 사이트입니다.\n\n여러분은 이 Skelton 사이트에 살을 붙여서 자신의 웹 사이트를 만들 수 있습니다. 그리고 이 작업은 사이트의 구조를 이해하는 것으로부터 시작됩니다.\n\n\n\n설정사항\n수정해야할 사항\n본 템플리트는 웹 사이트 중의 한 페이지로 bitReport\nwebsite라는 이름의 예제입니다. 환경 설정파일인\n_site.yml에 “샘플 웹 사이트”이라는 제목으로 연결되어\n있습니다. 만약에 예제 템플리트를 완성하려면 이 페이지의 이름을\n_site.yml에서의 create_website과 동일하게\n설정해야 합니다.\n웹 사이트 구성 파일\n웹 사이트를 구성하는 설정은 구성파일인 **_site.yml**에\n정의합니다.\n_site.yml 파일에서의 사용자가 설정해야할 항목은 다음과 같습니다.\nname: 웹 사이트의 이름\n헤더의 네비게이션 바의 왼쪽에 링크표시됩니다.\n\ntitle: 웹 사이트의 타이틀\n헤더의 네비게이션 바의 왼쪽에 링크표시됩니다.\n\ndescription: 웹 사이트의 설명\noutput_dir: 생성될 웹 사이트의 정적 HTML이 저장될 디렉토리\n“docs”로 기본설정됩니다. 이 디렉토리는 github page로 deploy할 때\n유용합니다.\n\nnavbar: 웹 사이트의 메뉴를 정의하는 섹션입니다.\n수정하지 않습니다.\n\nright: 웹 사이트의 메뉴를 정의합니다.\ntext는 메뉴 이름입니다.\nhref는 메뉴와 연결할 웹 페이지입니다. 확장자는\nhtml입니다.\nR markdown 파일과 동일하게 이름을 부여합니다.\n\nmenu는 서브메뉴를 정의합니다.\n빈 분리자를 만들기 위해서는 “- text:”—“를 사용합니다.\n\noutput: 웹 사이트 출력에 대한 설정입니다. 사용자가 수정하지\n않습니다.\n개별 페이지 구성 정보\n개별 페이지를 구성하기 위해서는 knitr YAML을 수정해야 합니다.\ntitle: 웹 페이지 제목입니다.\ndescription: 웹 페이지를 간단하게 소개하는 소개문입니다.\nauthor: 웹 페이지 컨텐츠 저작자 정보를 기술합니다.\nname: 저작자 이름\nurl: 저작자 개인 홈페이지 URL\naffiliation: 저작자 소속 회사/부서\naffiliation_url: 저작자 소속 회사/부서 홈페이지 URL\n\ndate: 컨텐츠를 생성한 날짜\noutput: 웹 사이트 출력에 대한 설정입니다.\ntoc: 목차를 출력할 지의 여부를 정의합니다. true이면 출력합니다.\ntoc_depth: 출력할 목차의 depth를 정의합니다. 3이면 3 depth까지\n표시합니다.\n\n\n이 예제 웹 사이트는 하나의 완성된 페이지를 만드는 것이 아닌, 가상의\nsite를 담은 Skelton만 제공합니다. 그러므로 개별 페이지의 내용에 신경쓸\n필요가 없습니다.\n\nData: USArrests\nUSArrests는 미국 주별 강력 범죄율을 기록한\n데이터입니다.\n이 데이터셋은 4개의 변수와 50개의 관측치로 구성된 데이터\n프레임(data.frame) 객체입니다.:\nMurder\nnumeric. 살인범 검거 건수(100,000건당)\n\nAssault\nnumeric. 폭행범 검거 건수(100,000건당)\n\nUrbanPop\nnumeric. 도시 인구 비율(백분율)\n\nRape\nnumeric. 강간범 검거 건수(100,000건당)\n\n\n\n# code here\n\n\n\n표(tables) 출력\n미국 주별 강력 범죄율을 기록한 데이터인 USArrests를 표로\n출력합니다.\n\n\nUSArrests %>% \n  tibble::rownames_to_column(\"주 (State)\") %>% \n  arrange(desc(Murder + Assault + Rape)) %>% \n  filter(row_number() <= 10) %>% \n  select(1:3, 5, 4) %>% \n  rename(`살인범` = Murder) %>% \n  rename(`폭행범` = Assault) %>% \n  rename(`강간범` = Rape) %>% \n  rename(`도시인구수(백분율)` = UrbanPop) %>%   \n  kableExtra::kbl(\n    caption = \"미국 범죄 상위 10개 주 현황\",\n    format.args = list(big.mark = \",\", digits = 1, scientific = 6)\n  ) %>% \n  kableExtra::kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %>% \n  kableExtra::add_header_above(c(\" \" = 1, \"범죄자수 (인구 만명 당)\" = 3, \" \" = 1)) %>% \n  kableExtra::kable_classic(full_width = TRUE) \n\n\n\nTable 1: 미국 범죄 상위 10개 주 현황\n\n\n\n\n\n범죄자수 (인구 만명 당)\n\n\n\n\n\n주 (State)\n\n\n살인범\n\n\n폭행범\n\n\n강간범\n\n\n도시인구수(백분율)\n\n\nFlorida\n\n\n15\n\n\n335\n\n\n32\n\n\n80\n\n\nNorth Carolina\n\n\n13\n\n\n337\n\n\n16\n\n\n45\n\n\nMaryland\n\n\n11\n\n\n300\n\n\n28\n\n\n67\n\n\nArizona\n\n\n8\n\n\n294\n\n\n31\n\n\n80\n\n\nNew Mexico\n\n\n11\n\n\n285\n\n\n32\n\n\n70\n\n\nCalifornia\n\n\n9\n\n\n276\n\n\n41\n\n\n91\n\n\nAlaska\n\n\n10\n\n\n263\n\n\n44\n\n\n48\n\n\nSouth Carolina\n\n\n14\n\n\n279\n\n\n22\n\n\n48\n\n\nNevada\n\n\n12\n\n\n252\n\n\n46\n\n\n81\n\n\nMichigan\n\n\n12\n\n\n255\n\n\n35\n\n\n74\n\n\n플롯(plots) 출력\n이 예제는 가상의 설명을 포함하고 있는, 그저 템플리트를 위한\n예제입니다.\n온도에 따른 수은의 증기압을 기록한 데이터인 pressure 데이터 프레임을\n산점도록 시각화합니다.\n\n\nplot(pressure, pch = 16, main = \"Relation between temperature and pressure\")\nlines(loess(pressure ~ temperature, pressure), col = \"steelblue\")\n\n\n\n\nFigure 1: 플롯 예제\n\n\n\n\n\n\n",
      "last_modified": "2022-12-16T11:39:10+09:00"
    },
    {
      "path": "index.html",
      "title": "텍스트 데이터 분석",
      "description": "“내가 생각하는 텍스트 분석과 기대하는 텍스트 분석을 정리해 봅니다.”\n",
      "author": [
        {
          "name": "김민성",
          "url": "https://minnsung-kim.github.io"
        }
      ],
      "date": "2022-10-01",
      "contents": "\n\nContents\n내가 기대하는 텍스트\n분석\n\n내가 기대하는 텍스트 분석\n2021년 국가기록원의 비공개기록물 공개재분류 R&D사업에 참여하여\n간단한 키워드 추출 작업을 했던 적이 있습니다. 그 때 당시 기록물들에 대한\n제대로 된 분석이 있으면 다양하게 활용을 할 수도 있다는 생각을\n하였습니다. 이러한 경험과 기록학을 배우는 학생으로써 앞으로 기록을\n관리하고 서비스하는 데에 텍스트 분석을 많이 활용하여 기록관리 분야가 좀\n더 발전하기를 기대합니다.\n\n\n\n\n\n\n\n",
      "last_modified": "2022-12-16T11:39:10+09:00"
    }
  ],
  "collections": []
}
